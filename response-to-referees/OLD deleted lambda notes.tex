\color{red}Quite different, more formal, reasoning confirms the misconception about programming. Lambda calculus ($\lambda$-calculus) is one of the very simplest of programming notations \cite{lambda}; it is just made up of strings of the four symbols $\lambda.()$ plus other symbols that have no pre-defined meanings. It is hard to think of a programming language that could look simpler, although of course anything can be written out in binary as a ``trivial'' sequence of \texttt{1}s and \texttt{0}s, but at least lambda calculus has a visible structure. 

Lambda calculus is powerful enough to do what any computer program can do; it is Turing Complete. 

Now consider this brief lambda expression: $\lambda t. (\lambda x. t (x x)) (\lambda x. t (x x))$. This expression  (the paradoxical combinator) allows us to easily define recursive functions \emph{without\/} any recursion. Such ``simple'' lambda calculus expressions are clearly profound. Indeed, lambda calculus has a place in the history of logic because it was the source of the first undecidable logic problems (the Halting Problem being perhaps a famous example). Lambda calculus thus proves that simple programs are \emph{not\/} simple; just because children can write programs does not mean anybody, including the children, can understand them. Indeed, ``programming is easy'' is contradicted by the Halting Problem, which shows that at least one trivial question about a program, whether it halts, is in general unanswerable.
\color{black}